{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Python Machine learning Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "# For preprocessing the data\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "# To split the dataset into train and test datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "# To model the Gaussian Navie Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# To calculate the accuracy score of the model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndisplay(df1.dtypes)\\nwith pd.option_context('display.max_rows', 10, 'display.max_columns', None):\\n    display(df1, df2)\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and merge data\n",
    "\n",
    "df1 = pd.read_csv('historical_data1_Q42008.txt', low_memory=False, sep=\"|\", header=None, \\\n",
    "                  names=['creditScore', 'FirstPayment', 'FirstTimeHomebuyer', 'Maturity', 'MetropolitanArea', 'MorgageInsurancePercentage', 'HouseUnits', 'OccupancyStatus', 'CombinedLoanToValue','DebtToIncome', 'UPB', 'OriginalLoanToValue', 'OrigninalInterestRate', 'Channel', 'PrepaymentPenaltyMorgageFlag', 'ProductType', 'PropertyState', 'PropertyType', 'ZipCode', 'LoanSequenceNumber', 'LoanPurpose', 'OriginalLoanTerm', 'NumberOfBorrowers', 'SellerName', 'ServiceName', 'SuperConformFlag', 'preHARPP'])\n",
    "                  # dtypes={'creditScore': np.int})\n",
    "df1.replace('',np.NaN)\n",
    "df1.replace('NaN',np.NaN)\n",
    "\n",
    "df2 = pd.read_csv('historical_data1_time_Q42008.txt', low_memory=False, sep=\"|\", header=None, names=['LoanSequenceNumber', 'MonthlyReportingPeriod', 'CurrentActualUPB', 'CurrentLoanDeliquencyStatus', 'LoanAge', 'MonthsToLegalMaturity', 'RepurchaseFlag', 'ModificationFlag', 'ZeroBalanceCode', 'ZeroBalanceEffectiveDate', 'CurrentInterestRate', 'CurrentDefferedUPB', 'DueDateLastOfPaidInstallment', 'MorgageInsuranceRecoveries', 'NetSalesProceeds', 'NonMorgageInsuranceRecoveries', 'Expenses', 'LegalCosts', 'MaintenanceAndPreservationCosts','TaxesAndInsurance', 'MiscellaneousExpenses', 'ActualLoss', 'ModificationCosts'])\n",
    "df2.replace('',np.NaN)\n",
    "df2.replace('NaN',np.NaN)\n",
    "\n",
    "# df = pd.merge(df1, df2, how='right', on = 'LoanSequenceNumber')\n",
    "\n",
    "'''\n",
    "display(df1.dtypes)\n",
    "with pd.option_context('display.max_rows', 10, 'display.max_columns', None):\n",
    "    display(df1, df2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with pd.option_context('display.max_rows', 100, 'display.max_columns', None):\\n    display(df)\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing columns\n",
    "df = pd.merge(df1, df2, how='right', on = 'LoanSequenceNumber')\n",
    "df.drop(df.columns[len(df.columns)-11:len(df.columns)], axis=1, inplace=True)\n",
    "df.drop(['OccupancyStatus', 'Channel', 'PrepaymentPenaltyMorgageFlag', 'ProductType', 'LoanPurpose', 'SellerName', 'ServiceName', 'SuperConformFlag', 'preHARPP', 'MonthsToLegalMaturity', 'RepurchaseFlag', 'CurrentDefferedUPB'], 1, inplace=True)\n",
    "\n",
    "'''with pd.option_context('display.max_rows', 100, 'display.max_columns', None):\n",
    "    display(df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get delinquent observations\n",
    "some_values = ['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14']\n",
    "default = df['CurrentLoanDeliquencyStatus'].isin(some_values)\n",
    "df['default'] = default\n",
    "# need to account for the fact that someone who defaults will always have an instance of not defaulting\n",
    "\n",
    "\n",
    "#with pd.option_context('display.max_rows', 100, 'display.max_columns', None):\n",
    "#    display(df[pd.notnull(df['ZeroBalanceCode'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdf = abc.loc[:,['default','creditScore', 'DebtToIncome', 'OriginalLoanToValue', 'OrigninalInterestRate']]\n",
    "\n",
    "'''\n",
    ", 'DebtToIncome', 'OriginalLoanToValue','OrigninalInterestRate', 'OriginalLoanTerm'\n",
    "'''\n",
    "#display(logdf[logdf['default'] == True])\n",
    "#logdf.drop_duplicates(subset='LoanSequenceNumber', inplace=True, keep='last')\n",
    "logdf['creditScore'].replace('   ', np.NaN, inplace=True)\n",
    "logdf['DebtToIncome'].replace('   ', np.NaN, inplace=True)\n",
    "logdf = logdf.dropna()\n",
    "logdf['creditScore'] = pd.to_numeric(logdf['creditScore'])\n",
    "logdf['DebtToIncome']= pd.to_numeric(logdf['DebtToIncome'])\n",
    "logdf = logdf.reset_index(drop=True)\n",
    "# a = logdf.loc[df['creditScore'] == isnull]\n",
    "\n",
    "\n",
    "#display(logdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default                  0\n",
       "creditScore              0\n",
       "DebtToIncome             0\n",
       "OriginalLoanToValue      0\n",
       "OrigninalInterestRate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode the categorical columns\n",
    "le = preprocessing.LabelEncoder()\n",
    "default_cat = le.fit_transform(logdf.default)\n",
    "creditScore_cat = le.fit_transform(logdf.creditScore)\n",
    "DebtToIncome_cat = le.fit_transform(logdf.DebtToIncome)\n",
    "OriginalLoanToValue_cat = le.fit_transform(logdf.OriginalLoanToValue)\n",
    "OrigninalInterestRate_cat = le.fit_transform(logdf.OrigninalInterestRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize the encoded categorical columns\n",
    "logdf['default_cat'] = default_cat\n",
    "logdf['creditScore_cat'] = creditScore_cat\n",
    "logdf['DebtToIncome_cat'] = DebtToIncome_cat\n",
    "logdf['OriginalLoanToValue_cat'] = OriginalLoanToValue_cat\n",
    "logdf['OrigninalInterestRate_cat'] = OrigninalInterestRate_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_fields=['default','creditScore','DebtToIncome','OriginalLoanToValue','OrigninalInterestRate']\n",
    "logdfnew = logdf.drop(dummy_fields, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdfnew = logdfnew.reindex_axis(['creditScore_cat','DebtToIncome_cat','OriginalLoanToValue_cat','OrigninalInterestRate_cat','default_cat'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting Data Up Into Training and Testing\n",
    "features = logdfnew.values[:,:4]\n",
    "target = logdfnew.values[:,4]\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,target, test_size = 0.33, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a GaussianNB classifier and predict \n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, target_train)\n",
    "target_pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[260,  49,  49, 229],\n",
       "       [116,  18,  64, 371],\n",
       "       [280,  39,  36, 290],\n",
       "       ..., \n",
       "       [148,  42,  69, 429],\n",
       "       [160,  39,  89, 371],\n",
       "       [250,  30,  69, 128]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features tested on\n",
    "features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preciction Results\n",
    "target_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98182167222894945"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test accuracy of model\n",
    "accuracy_score(target_test, target_pred, normalize = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
